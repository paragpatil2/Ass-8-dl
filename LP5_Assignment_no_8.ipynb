{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j-jTUIGjxog"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# There are 10 image classes in this dataset and each class has a mapping corresponding to the following labels:\n",
        "\n",
        "#0 T-shirt/top\n",
        "#1 Trouser\n",
        "#2 pullover\n",
        "#3 Dress\n",
        "#4 Coat\n",
        "#5 sandals\n",
        "#6 shirt\n",
        "#7 sneaker\n",
        "#8 bag\n",
        "#9 ankle boot\n",
        "\n",
        "# https://ml-course.github.io/master/09%20-%20Convolutional%20Neural%20Networks.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPJO4exOTkPW"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6gwec8jYnpV"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-c-5JWYPPqT"
      },
      "outputs": [],
      "source": [
        "# Next, we will preprocess the data by scaling the pixel values to be between 0 and 1, and then reshaping the images to be 28x28 pixels.\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# 28, 28 comes from width, height, 1 comes from the number of channels\n",
        "# -1 means that the length in that dimension is inferred.\n",
        "# This is done based on the constraint that the number of elements in an ndarray or Tensor when reshaped must remain the same.\n",
        "\n",
        "# each image is a row vector (784 elements) and there are lots of such rows (let it be n, so there are 784n elements). So TensorFlow can infer that -1 is n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Th54tYxXPyiB"
      },
      "outputs": [],
      "source": [
        "# converting the training_images array to 4 dimensional array with sizes 60000, 28, 28, 1 for 0th to 3rd dimension. \n",
        "\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TMVZKAtP4BL"
      },
      "outputs": [],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCYL-C4PP_ki"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ocddGOxQFiM"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txTuSANLQJ1S"
      },
      "outputs": [],
      "source": [
        "# We will use a convolutional neural network (CNN) to classify the fashion items. \n",
        "# The CNN will consist of multiple convolutional layers followed by max pooling, \n",
        "# dropout, and dense layers. Here is the code for the model:\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    # 32 filters (default), randomly initialized\n",
        "    # 3*3 is Size of Filter\n",
        "    # 28,28,1 size of Input Image\n",
        "    # No zero-padding: every output 2 pixels less in every dimension\n",
        "    # in Paramter shwon 320 is value of weights: (3x3 filter weights + 32 bias) * 32 filters\n",
        "    # 32*3*3=288(Total)+32(bias)= 320\n",
        "\n",
        "\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    # It shown 13 * 13 size image with 32 channel or filter or depth.\n",
        "\n",
        "    keras.layers.Dropout(0.25),\n",
        "    # Reduce Overfitting of Training sample drop out 25% Neuron\n",
        "\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    # Deeper layers use 64 filters\n",
        "    # 3*3 is Size of Filter\n",
        "    # Observe how the input image on 28x28x1 is transformed to a 3x3x64 feature map\n",
        "    # 13(Size)-3(Filter Size )+1(bias)=11 Size for Width and Height with 64 Depth or filtter or channel\n",
        "    # in Paramter shwon 18496 is value of weights: (3x3 filter weights + 64 bias) * 64 filters\n",
        "    # 64*3*3=576+1=577*32 + 32(bias)=18496\n",
        "\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    # It shown 5 * 5 size image with 64 channel or filter or depth.\n",
        "\n",
        "    keras.layers.Dropout(0.25),\n",
        "        \n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    # Deeper layers use 128 filters\n",
        "    # 3*3 is Size of Filter\n",
        "    # Observe how the input image on 28x28x1 is transformed to a 3x3x128 feature map\n",
        "    # It show 5(Size)-3(Filter Size )+1(bias)=3 Size for Width and Height with 64 Depth or filtter or channel\n",
        "    # 128*3*3=1152+1=1153*64 + 64(bias)= 73856\n",
        "\n",
        "    # To classify the images, we still need a Dense and Softmax layer.\n",
        "    # We need to flatten the 3x3x128 feature map to a vector of size 1152\n",
        "    # https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    # 128 Size of Node in Dense Layer\n",
        "    # 1152*128 = 147584\n",
        "\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "    # 10 Size of Node another Dense Layer\n",
        "    # 128*10+10 bias= 1290\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzBjU3g3idgx"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ziWNG1QTJh",
        "outputId": "f4fecfd8-18f0-451f-9778-4ea01e3356da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.6013 - accuracy: 0.7769 - val_loss: 0.3916 - val_accuracy: 0.8592\n",
            "Epoch 2/10\n",
            "1852/1875 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8589"
          ]
        }
      ],
      "source": [
        "# Compile and Train the Model\n",
        "# After defining the model, we will compile it and train it on the training data.\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# 1875 is a number of batches. By default batches contain 32 samles.60000 / 32 = 1875\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhG8LcfRQnQl"
      },
      "outputs": [],
      "source": [
        "# Finally, we will evaluate the performance of the model on the test data.\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}